# The local model you expect to be present
OLLAMA_MODEL=llama3.1:8b

# The embedding model for vector operations
OLLAMA_MODEL_EMBED=nomic-embed-text

# Optional: override host (e.g., WSL/remote)
# OLLAMA_HOST=http://127.0.0.1:11434